#!/usr/bin/env python3
"""
Yevedia MLX Fine-Tuning Script
Fine-tune Phi-3 avec LoRA sur Apple Silicon
"""

import subprocess
import sys
import os
from pathlib import Path

# Chemins
SCRIPT_DIR = Path(__file__).parent
TRAINING_DIR = SCRIPT_DIR.parent  # training/
DATA_DIR = TRAINING_DIR / "data"  # training/data
MODELS_DIR = TRAINING_DIR / "models"  # training/models
ADAPTERS_DIR = MODELS_DIR / "adapters"

# Configuration du fine-tuning
CONFIG = {
    # Mod√®le de base TinyLlama (petit et rapide ~500MB)
    "base_model": "mlx-community/TinyLlama-1.1B-Chat-v1.0-4bit",
    
    # Param√®tres LoRA
    "lora_rank": 8,           # Rang de la d√©composition LoRA (4-16)
    "lora_alpha": 16,         # Facteur d'√©chelle
    "lora_dropout": 0.05,     # Dropout pour r√©gularisation
    
    # Param√®tres d'entra√Ænement
    "batch_size": 4,          # Taille du batch (ajuster selon RAM)
    "learning_rate": 1e-5,    # Taux d'apprentissage
    "epochs": 3,              # Nombre d'√©poques
    "max_seq_length": 512,    # Longueur max des s√©quences
    
    # Sauvegarde
    "save_every": 100,        # Sauvegarder tous les N steps
    "adapter_path": str(ADAPTERS_DIR / "yevedia-lora"),
}

def check_dependencies():
    """V√©rifier et installer les d√©pendances"""
    print("üîç V√©rification des d√©pendances...")
    
    required = ['mlx', 'mlx_lm', 'transformers', 'huggingface_hub']
    missing = []
    
    for pkg in required:
        try:
            __import__(pkg.replace('-', '_'))
        except ImportError:
            missing.append(pkg)
    
    if missing:
        print(f"üì¶ Installation des d√©pendances manquantes: {missing}")
        subprocess.check_call([
            sys.executable, "-m", "pip", "install", 
            "mlx", "mlx-lm", "transformers", "huggingface_hub", "numpy"
        ])
        print("‚úÖ D√©pendances install√©es!")
    else:
        print("‚úÖ Toutes les d√©pendances sont install√©es")

def check_data():
    """V√©rifier que les donn√©es d'entra√Ænement existent"""
    train_file = DATA_DIR / "train.jsonl"
    valid_file = DATA_DIR / "valid.jsonl"
    
    if not train_file.exists() or not valid_file.exists():
        print("‚ö†Ô∏è  Donn√©es d'entra√Ænement non trouv√©es!")
        print("   Ex√©cution de l'export des donn√©es...")
        
        export_script = SCRIPT_DIR / "export_data.py"
        subprocess.check_call([sys.executable, str(export_script)])
    
    # Compter les exemples
    with open(train_file, 'r') as f:
        train_count = sum(1 for _ in f)
    with open(valid_file, 'r') as f:
        valid_count = sum(1 for _ in f)
    
    print(f"üìä Donn√©es disponibles:")
    print(f"   - Train: {train_count} exemples")
    print(f"   - Validation: {valid_count} exemples")
    
    return train_count, valid_count

def run_finetuning():
    """Lancer le fine-tuning avec MLX"""
    print("\nüöÄ D√©marrage du fine-tuning MLX...")
    print("=" * 60)
    
    # Cr√©er le dossier des adaptateurs
    ADAPTERS_DIR.mkdir(parents=True, exist_ok=True)
    
    # Commande MLX pour le fine-tuning LoRA (mlx-lm >= 0.30 nouvelle syntaxe)
    cmd = [
        sys.executable, "-m", "mlx_lm", "lora",
        "--model", CONFIG["base_model"],
        "--train",
        "--data", str(DATA_DIR),
        "--adapter-path", CONFIG["adapter_path"],
        "--batch-size", str(CONFIG["batch_size"]),
        "--num-layers", "16",
        "--iters", str(CONFIG["epochs"] * 100),
        "--learning-rate", str(CONFIG["learning_rate"]),
        "--save-every", str(CONFIG["save_every"]),
    ]
    
    print(f"üìù Commande: {' '.join(cmd)}")
    print("\n" + "=" * 60)
    
    try:
        # Ex√©cuter le fine-tuning
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # Afficher la sortie en temps r√©el
        for line in process.stdout:
            print(line, end='')
        
        process.wait()
        
        if process.returncode == 0:
            print("\n" + "=" * 60)
            print("‚úÖ Fine-tuning termin√© avec succ√®s!")
            print(f"   Adaptateur sauvegard√©: {CONFIG['adapter_path']}")
            return True
        else:
            print(f"\n‚ùå Erreur lors du fine-tuning (code: {process.returncode})")
            return False
            
    except Exception as e:
        print(f"\n‚ùå Erreur: {e}")
        return False

def test_model():
    """Tester le mod√®le fine-tun√©"""
    print("\nüß™ Test du mod√®le fine-tun√©...")
    
    test_prompts = [
        "Qui es-tu ?",
        "Qui est Obed ?",
        "Que peux-tu faire ?",
    ]
    
    cmd_base = [
        sys.executable, "-m", "mlx_lm.generate",
        "--model", CONFIG["base_model"],
        "--adapter-path", CONFIG["adapter_path"],
        "--max-tokens", "100",
    ]
    
    for prompt in test_prompts:
        print(f"\nüìù Prompt: {prompt}")
        cmd = cmd_base + ["--prompt", prompt]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            print(f"ü§ñ R√©ponse: {result.stdout}")
        except Exception as e:
            print(f"‚ùå Erreur: {e}")

def export_to_gguf():
    """Convertir le mod√®le en format GGUF pour Ollama"""
    print("\nüì¶ Conversion en GGUF pour Ollama...")
    
    output_path = MODELS_DIR / "yevedia-phi3.gguf"
    
    # La conversion GGUF n√©cessite llama.cpp
    print("‚ö†Ô∏è  Pour utiliser avec Ollama, suivez ces √©tapes:")
    print("")
    print("1. Fusionner les adaptateurs LoRA avec le mod√®le de base:")
    print(f"   python -m mlx_lm.fuse \\")
    print(f"       --model {CONFIG['base_model']} \\")
    print(f"       --adapter-path {CONFIG['adapter_path']} \\")
    print(f"       --save-path {MODELS_DIR}/yevedia-phi3-merged")
    print("")
    print("2. Convertir en GGUF avec llama.cpp:")
    print(f"   python llama.cpp/convert-hf-to-gguf.py \\")
    print(f"       {MODELS_DIR}/yevedia-phi3-merged \\")
    print(f"       --outtype q4_0 \\")
    print(f"       --outfile {output_path}")
    print("")
    print("3. Cr√©er un Modelfile Ollama:")
    print(f"   FROM {output_path}")
    print("")
    print("4. Importer dans Ollama:")
    print(f"   ollama create yevedia -f Modelfile")

def main(auto_mode=False):
    print("=" * 60)
    print("üß† Yevedia MLX Fine-Tuning System")
    print("   Fine-tune Phi-3 pour ton assistant personnel")
    print("=" * 60)
    print()
    
    # √âtape 1: D√©pendances
    check_dependencies()
    
    # √âtape 2: Donn√©es
    train_count, valid_count = check_data()
    
    if train_count < 5:
        print("\n‚ö†Ô∏è  Pas assez de donn√©es d'entra√Ænement!")
        print("   Ajoutez plus de conversations et m√©moires dans Yevedia.")
        print("   Minimum recommand√©: 50+ exemples")
        
        if not auto_mode:
            response = input("\nContinuer quand m√™me? (o/n): ")
            if response.lower() != 'o':
                print("Annul√©.")
                return False
        else:
            print("\n[AUTO] Continuation avec les donn√©es disponibles...")
    
    # √âtape 3: Fine-tuning
    print("\n" + "=" * 60)
    print("‚è≥ Le fine-tuning va commencer...")
    print("   Cela peut prendre 10-30 minutes selon votre Mac.")
    print("=" * 60)
    
    if not auto_mode:
        response = input("\nD√©marrer le fine-tuning? (o/n): ")
        if response.lower() != 'o':
            print("Annul√©.")
            return False
    else:
        print("\n[AUTO] D√©marrage automatique...")
    
    success = run_finetuning()
    
    if success:
        if not auto_mode:
            response = input("\nTester le mod√®le fine-tun√©? (o/n): ")
            if response.lower() == 'o':
                test_model()
        
        # √âtape 5: Export
        export_to_gguf()
    
    print("\n" + "=" * 60)
    print("‚úÖ Processus termin√©!" if success else "‚ùå Entra√Ænement √©chou√©!")
    print("=" * 60)
    
    return success

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='Yevedia MLX Fine-Tuning')
    parser.add_argument('--auto', action='store_true', help='Mode automatique sans confirmation')
    args = parser.parse_args()
    
    success = main(auto_mode=args.auto)
    sys.exit(0 if success else 1)

