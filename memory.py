"""
Yevedia AI Chat - Syst√®me de M√©moire Persistante
Base de donn√©es SQLite pour stocker les souvenirs de l'IA
"""

import sqlite3
import json
from datetime import datetime
from pathlib import Path

# Chemin de la base de donn√©es
DB_PATH = Path(__file__).parent / "memory.db"


def get_connection():
    """Cr√©er une connexion √† la base de donn√©es"""
    conn = sqlite3.connect(str(DB_PATH))
    conn.row_factory = sqlite3.Row
    return conn


def init_database():
    """Initialiser la base de donn√©es avec les tables n√©cessaires"""
    conn = get_connection()
    cursor = conn.cursor()
    
    # Table des souvenirs/m√©moires
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS memories (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            title TEXT NOT NULL,
            content TEXT NOT NULL,
            category TEXT NOT NULL DEFAULT 'knowledge',
            priority INTEGER DEFAULT 1,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            is_active BOOLEAN DEFAULT 1
        )
    """)
    
    # Table des conversations (historique)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS conversations (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            session_id TEXT NOT NULL,
            title TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # Table des messages
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            conversation_id INTEGER,
            role TEXT NOT NULL,
            content TEXT NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (conversation_id) REFERENCES conversations(id)
        )
    """)
    
    # Table des embeddings (pour recherche s√©mantique future)
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS embeddings (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            memory_id INTEGER,
            embedding BLOB,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (memory_id) REFERENCES memories(id)
        )
    """)
    
    # Table des documents
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS documents (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            content TEXT NOT NULL,
            type TEXT DEFAULT 'text/plain',
            size INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            is_active BOOLEAN DEFAULT 1
        )
    """)
    
    # Table du cache de recherche web
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS web_search_cache (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            query TEXT NOT NULL,
            query_normalized TEXT NOT NULL,
            results TEXT NOT NULL,
            source TEXT DEFAULT 'duckduckgo',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            expires_at TIMESTAMP,
            hit_count INTEGER DEFAULT 0
        )
    """)
    
    # Index pour recherche rapide par query normalis√©e
    cursor.execute("""
        CREATE INDEX IF NOT EXISTS idx_web_cache_query 
        ON web_search_cache(query_normalized)
    """)
    
    conn.commit()
    conn.close()
    # Note: Ne pas utiliser print() ici car cela pollue la sortie JSON


# ============================================
# GESTION DES SOUVENIRS (MEMORIES)
# ============================================

def add_memory(title: str, content: str, category: str = "knowledge", priority: int = 1) -> dict:
    """Ajouter un nouveau souvenir √† la m√©moire"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        INSERT INTO memories (title, content, category, priority)
        VALUES (?, ?, ?, ?)
    """, (title, content, category, priority))
    
    memory_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    return {
        "id": memory_id,
        "title": title,
        "content": content,
        "category": category,
        "priority": priority,
        "success": True
    }


def add_memory_base64(title_b64: str, content_b64: str, category: str = "knowledge", priority: int = 1) -> dict:
    """Ajouter un souvenir avec titre et contenu encod√©s en Base64 (pour √©viter les probl√®mes d'√©chappement)"""
    import base64
    
    try:
        title = base64.b64decode(title_b64).decode('utf-8')
        content = base64.b64decode(content_b64).decode('utf-8')
    except Exception as e:
        return {"success": False, "error": f"Erreur d√©codage Base64: {str(e)}"}
    
    return add_memory(title, content, category, priority)


def get_all_memories(active_only: bool = True) -> list:
    """R√©cup√©rer tous les souvenirs"""
    conn = get_connection()
    cursor = conn.cursor()
    
    if active_only:
        cursor.execute("""
            SELECT * FROM memories 
            WHERE is_active = 1 
            ORDER BY priority DESC, created_at DESC
        """)
    else:
        cursor.execute("SELECT * FROM memories ORDER BY priority DESC, created_at DESC")
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]


def get_memories_by_category(category: str) -> list:
    """R√©cup√©rer les souvenirs par cat√©gorie"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT * FROM memories 
        WHERE category = ? AND is_active = 1
        ORDER BY priority DESC, created_at DESC
    """, (category,))
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]


def update_memory(memory_id: int, title: str = None, content: str = None, 
                  category: str = None, priority: int = None) -> dict:
    """Mettre √† jour un souvenir existant"""
    conn = get_connection()
    cursor = conn.cursor()
    
    updates = []
    values = []
    
    if title is not None:
        updates.append("title = ?")
        values.append(title)
    if content is not None:
        updates.append("content = ?")
        values.append(content)
    if category is not None:
        updates.append("category = ?")
        values.append(category)
    if priority is not None:
        updates.append("priority = ?")
        values.append(priority)
    
    updates.append("updated_at = ?")
    values.append(datetime.now().isoformat())
    values.append(memory_id)
    
    cursor.execute(f"""
        UPDATE memories 
        SET {', '.join(updates)}
        WHERE id = ?
    """, values)
    
    conn.commit()
    conn.close()
    
    return {"id": memory_id, "success": True}


def delete_memory(memory_id: int, soft_delete: bool = True) -> dict:
    """Supprimer un souvenir (soft delete par d√©faut)"""
    conn = get_connection()
    cursor = conn.cursor()
    
    if soft_delete:
        cursor.execute("UPDATE memories SET is_active = 0 WHERE id = ?", (memory_id,))
    else:
        cursor.execute("DELETE FROM memories WHERE id = ?", (memory_id,))
    
    conn.commit()
    conn.close()
    
    return {"id": memory_id, "deleted": True}


def clear_all_memories() -> dict:
    """Effacer toute la m√©moire"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("UPDATE memories SET is_active = 0")
    
    conn.commit()
    conn.close()
    
    return {"success": True, "message": "M√©moire effac√©e"}


def search_memories(query: str) -> list:
    """Rechercher dans les souvenirs (recherche simple)"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT * FROM memories 
        WHERE is_active = 1 
        AND (title LIKE ? OR content LIKE ?)
        ORDER BY priority DESC
    """, (f"%{query}%", f"%{query}%"))
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]


def build_memory_context() -> str:
    """Construire le contexte m√©moire pour le prompt"""
    memories = get_all_memories()
    
    if not memories:
        return ""
    
    context = "Contexte et informations importantes √† retenir:\n\n"
    
    # Grouper par cat√©gorie
    categories = {
        "identity": "üë§ Identit√©",
        "preferences": "‚öôÔ∏è Pr√©f√©rences", 
        "knowledge": "üìö Connaissances",
        "instructions": "üìã Instructions"
    }
    
    for cat_key, cat_name in categories.items():
        cat_memories = [m for m in memories if m["category"] == cat_key]
        if cat_memories:
            context += f"{cat_name}:\n"
            for mem in cat_memories:
                context += f"  - {mem['title']}: {mem['content']}\n"
            context += "\n"
    
    context += "Utilise ces informations pour personnaliser tes r√©ponses.\n\n"
    
    return context


# ============================================
# GESTION DES DOCUMENTS
# ============================================

def add_document(name: str, content: str, doc_type: str = "text/plain", size: int = 0) -> dict:
    """Ajouter un nouveau document"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        INSERT INTO documents (name, content, type, size)
        VALUES (?, ?, ?, ?)
    """, (name, content, doc_type, size))
    
    doc_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    return {
        "id": doc_id,
        "name": name,
        "type": doc_type,
        "size": size,
        "success": True
    }


def add_document_base64(name: str, base64_content: str, doc_type: str = "text/plain", size: int = 0) -> dict:
    """Ajouter un document avec contenu encod√© en Base64"""
    import base64
    
    # D√©coder le contenu Base64
    try:
        content = base64.b64decode(base64_content).decode('utf-8')
    except Exception as e:
        return {"success": False, "error": f"Erreur d√©codage Base64: {str(e)}"}
    
    # Utiliser la fonction standard
    return add_document(name, content, doc_type, size)


def get_all_documents(active_only: bool = False) -> list:
    """R√©cup√©rer tous les documents avec leur contenu et statut"""
    conn = get_connection()
    cursor = conn.cursor()
    
    if active_only:
        cursor.execute("""
            SELECT id, name, content, type, size, created_at, is_active FROM documents 
            WHERE is_active = 1 
            ORDER BY created_at DESC
        """)
    else:
        cursor.execute("SELECT id, name, content, type, size, created_at, is_active FROM documents ORDER BY created_at DESC")
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]


def get_document_content(doc_id: int) -> str:
    """R√©cup√©rer le contenu d'un document"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("SELECT content FROM documents WHERE id = ? AND is_active = 1", (doc_id,))
    row = cursor.fetchone()
    conn.close()
    
    return row["content"] if row else ""


def delete_document(doc_id: int) -> dict:
    """Supprimer un document"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("UPDATE documents SET is_active = 0 WHERE id = ?", (doc_id,))
    
    conn.commit()
    conn.close()
    
    return {"id": doc_id, "deleted": True}


def clear_all_documents() -> dict:
    """Supprimer tous les documents"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("UPDATE documents SET is_active = 0")
    
    conn.commit()
    conn.close()
    
    return {"success": True, "message": "Documents supprim√©s"}


def toggle_document(doc_id: int, is_active: int) -> dict:
    """Activer ou d√©sactiver un document"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("UPDATE documents SET is_active = ? WHERE id = ?", (is_active, doc_id))
    
    conn.commit()
    conn.close()
    
    return {"id": doc_id, "is_active": is_active, "success": True}


# ============================================
# CACHE DE RECHERCHE WEB
# ============================================

def normalize_query(query: str) -> str:
    """Normaliser une requ√™te pour la comparaison (minuscules, sans espaces multiples)"""
    import re
    normalized = query.lower().strip()
    normalized = re.sub(r'\s+', ' ', normalized)  # Remplacer espaces multiples
    normalized = re.sub(r'[^\w\s]', '', normalized)  # Supprimer ponctuation
    return normalized


def get_cached_search(query: str, max_age_hours: int = 24) -> dict:
    """
    R√©cup√©rer une recherche en cache si elle existe et n'est pas expir√©e.
    
    Args:
        query: La requ√™te de recherche
        max_age_hours: √Çge maximum du cache en heures (d√©faut: 24h)
    
    Returns:
        dict avec les r√©sultats si trouv√©, None sinon
    """
    conn = get_connection()
    cursor = conn.cursor()
    
    normalized = normalize_query(query)
    
    # Chercher dans le cache (pas expir√©)
    cursor.execute("""
        SELECT id, query, results, source, created_at, hit_count
        FROM web_search_cache 
        WHERE query_normalized = ?
        AND datetime(created_at, '+' || ? || ' hours') > datetime('now')
        ORDER BY created_at DESC
        LIMIT 1
    """, (normalized, max_age_hours))
    
    row = cursor.fetchone()
    
    if row:
        # Incr√©menter le compteur de hits
        cursor.execute("""
            UPDATE web_search_cache 
            SET hit_count = hit_count + 1 
            WHERE id = ?
        """, (row["id"],))
        conn.commit()
        conn.close()
        
        return {
            "success": True,
            "cached": True,
            "query": row["query"],
            "results": json.loads(row["results"]),
            "source": row["source"] + " (cache)",
            "cached_at": row["created_at"],
            "hit_count": row["hit_count"] + 1
        }
    
    conn.close()
    return None


def cache_search_results(query: str, results: list, source: str = "duckduckgo") -> dict:
    """
    Enregistrer les r√©sultats d'une recherche dans le cache.
    
    Args:
        query: La requ√™te originale
        results: Liste des r√©sultats de recherche
        source: Source de la recherche (duckduckgo, google, etc.)
    
    Returns:
        dict avec le statut de l'op√©ration
    """
    conn = get_connection()
    cursor = conn.cursor()
    
    normalized = normalize_query(query)
    results_json = json.dumps(results, ensure_ascii=False)
    
    # Supprimer les anciennes entr√©es pour cette requ√™te
    cursor.execute("""
        DELETE FROM web_search_cache 
        WHERE query_normalized = ?
    """, (normalized,))
    
    # Ins√©rer le nouveau cache
    cursor.execute("""
        INSERT INTO web_search_cache (query, query_normalized, results, source)
        VALUES (?, ?, ?, ?)
    """, (query, normalized, results_json, source))
    
    cache_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    return {
        "success": True,
        "id": cache_id,
        "query": query,
        "results_count": len(results)
    }


def get_search_cache_stats() -> dict:
    """Obtenir les statistiques du cache de recherche"""
    conn = get_connection()
    cursor = conn.cursor()
    
    # Total d'entr√©es
    cursor.execute("SELECT COUNT(*) as total FROM web_search_cache")
    total = cursor.fetchone()["total"]
    
    # Total de hits
    cursor.execute("SELECT SUM(hit_count) as hits FROM web_search_cache")
    row = cursor.fetchone()
    total_hits = row["hits"] if row["hits"] else 0
    
    # Requ√™tes les plus consult√©es
    cursor.execute("""
        SELECT query, hit_count, created_at 
        FROM web_search_cache 
        ORDER BY hit_count DESC 
        LIMIT 5
    """)
    top_queries = [dict(row) for row in cursor.fetchall()]
    
    conn.close()
    
    return {
        "total_cached": total,
        "total_hits": total_hits,
        "top_queries": top_queries
    }


def clear_search_cache(older_than_hours: int = None) -> dict:
    """
    Vider le cache de recherche.
    
    Args:
        older_than_hours: Si sp√©cifi√©, ne supprimer que les entr√©es plus anciennes
    """
    conn = get_connection()
    cursor = conn.cursor()
    
    if older_than_hours:
        cursor.execute("""
            DELETE FROM web_search_cache 
            WHERE datetime(created_at, '+' || ? || ' hours') < datetime('now')
        """, (older_than_hours,))
    else:
        cursor.execute("DELETE FROM web_search_cache")
    
    deleted = cursor.rowcount
    conn.commit()
    conn.close()
    
    return {"success": True, "deleted": deleted}


# ============================================
# GESTION DES CONVERSATIONS
# ============================================

def create_conversation(session_id: str, title: str = None) -> dict:
    """Cr√©er une nouvelle conversation"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        INSERT INTO conversations (session_id, title)
        VALUES (?, ?)
    """, (session_id, title or "Nouvelle conversation"))
    
    conversation_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    return {"id": conversation_id, "session_id": session_id}


def add_message(conversation_id: int, role: str, content: str) -> dict:
    """Ajouter un message √† une conversation"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        INSERT INTO messages (conversation_id, role, content)
        VALUES (?, ?, ?)
    """, (conversation_id, role, content))
    
    message_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    return {"id": message_id, "success": True}


def get_conversation_messages(conversation_id: int) -> list:
    """R√©cup√©rer les messages d'une conversation"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT * FROM messages 
        WHERE conversation_id = ?
        ORDER BY created_at ASC
    """, (conversation_id,))
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]


def get_all_conversations() -> list:
    """R√©cup√©rer toutes les conversations"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT * FROM conversations 
        ORDER BY updated_at DESC
    """)
    
    rows = cursor.fetchall()
    conn.close()
    
    return [dict(row) for row in rows]


# ============================================
# STATISTIQUES
# ============================================

def get_memory_stats() -> dict:
    """Obtenir les statistiques de la m√©moire"""
    conn = get_connection()
    cursor = conn.cursor()
    
    cursor.execute("SELECT COUNT(*) as total FROM memories WHERE is_active = 1")
    total = cursor.fetchone()["total"]
    
    cursor.execute("""
        SELECT category, COUNT(*) as count 
        FROM memories 
        WHERE is_active = 1 
        GROUP BY category
    """)
    by_category = {row["category"]: row["count"] for row in cursor.fetchall()}
    
    cursor.execute("SELECT COUNT(*) as total FROM conversations")
    conversations = cursor.fetchone()["total"]
    
    cursor.execute("SELECT COUNT(*) as total FROM messages")
    messages = cursor.fetchone()["total"]
    
    conn.close()
    
    return {
        "total_memories": total,
        "by_category": by_category,
        "total_conversations": conversations,
        "total_messages": messages
    }


# ============================================
# INITIALISATION
# ============================================

if __name__ == "__main__":
    # Initialiser la base de donn√©es
    init_database()
    print("‚úÖ Base de donn√©es initialis√©e")
    
    # Afficher les stats
    stats = get_memory_stats()
    print(f"\nüìä Statistiques:")
    print(f"   Souvenirs: {stats['total_memories']}")
    print(f"   Conversations: {stats['total_conversations']}")
    print(f"   Messages: {stats['total_messages']}")
    
    # Exemple d'ajout
    print("\nüí° Exemple d'utilisation:")
    print('   memory.add_memory("Mon nom", "Je suis Jean", "identity")')
    print('   memory.get_all_memories()')
    print('   memory.build_memory_context()')
